{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c491902a",
   "metadata": {},
   "source": [
    "## 파이토치 기초(5) - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7038db4",
   "metadata": {},
   "source": [
    "* day 1 - 텐서와 Autograd : https://dacon.io/codeshare/4478\n",
    "* day 2 - 신경망모델 구현하기 : https://dacon.io/codeshare/4495\n",
    "* day 3 - DNN : https://dacon.io/codeshare/4532\n",
    "* day 4 - CNN : https://dacon.io/codeshare/4537\n",
    "* day 5 - AutoEncoder 오토 인코더 : https://dacon.io/codeshare/4551"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd3d7a",
   "metadata": {},
   "source": [
    "#### 개요\n",
    "* I live to eat 과 I eat to live는 모두 같은 단어로 이루어졌지만 'live'와 'eat'의 위치가 뒤바뀌면 뜻이 완전히 달라짐을 알 수 있습니다.\n",
    "* 일반적인 신경망 구조로는 단어의 특징만 잡아내기 때문에 이 변화를 인식하기 힘듭니다.\n",
    "* 오늘의 목표는 데이터의 순서가 주는 정보까지 인지하는 새로운 형태의 신경망을 배우는 것입니다.\n",
    "* RNN(Recurrent Neural Network)은 데이터가 나열된 순차적 데이터(Sequential Data) 혹은 시계열 데이터(Time Series Data)의 정보를 받아 전체 내용을 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25b3e2",
   "metadata": {},
   "source": [
    "#### RNN\n",
    "* RNN은 정해지지 않은 길이의 배열을 읽고 설명하는 신경망입니다. RNN의 출력은 순차적 데이터의 흐름을 모두 내포합니다.\n",
    "* RNN은 시계열 데이터의 정보를 하나씩 입력받을 때마다 지금까지 입력된 벡터들을 종합해 은닉 벡터(hidden vector)를 만들어냅니다.\n",
    "* RNN 계열 신경망들은 대표적인 시계열 데이터인 텍스트와 자연어를 처리하고 학습하는 데 주로 사용됩니다. 오늘날에는 LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit) 등 응용 RNN이 개발되어 언어 모델링(Language Modeling), 텍스트 감정 분석(text sentiment analysis), 기계 번역(Machin Translation) 등의 분야에 활발하게 이용되고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedadd24",
   "metadata": {},
   "source": [
    "### 영화 리뷰 감정 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a852343",
   "metadata": {},
   "source": [
    "* 데이터의 순서 정보를 학습한다는 점에서 RNN은 CIFAR-10 같은 정적 데이터보다는 동영상, 자연어, 주가 등 동적인 데이터를 이용할 때 성능이 극대화 됩니다.\n",
    "* IMDB는 텍스트 형태의 데이터셋으로 영화리뷰 5만 건으로 이루어져 있습니다. 각 리뷰는 다수의 영어 문장으로 구성되어 있으며, 긍정적 영화 리뷰는 2로, 부정적인 영화 리뷰는 1로 레이블링 되었습니다. \n",
    "* 영화 리뷰 텍스트를 RNN에 입력해 영화평 전체 내용을 압축하고 이렇게 압축된 리뷰가 긍정적인지 부정적인지 판단해주는 간단한 분류 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752e578",
   "metadata": {},
   "source": [
    "#### cf) 토크나이징과 워드 임베딩\n",
    "* 자연어 텍스트를 인공신경망에 입력시키려면 전처리 과정을 거쳐 데이터를 숫자로 나타내야 합니다.\n",
    "* 가장 먼저 해야 할 일은 '언어의 최소 단위'인 토큰(token)으로 나누는 것입니다.\n",
    "* 간단한 데이터셋이라면 파이썬의 split()함수를 사용해 단어단위로 토크나이징(tokenizing)해도 큰 문제는 없지만, 더 좋은 성능을 내고 싶다면 SpaCy같은 오픈 소스 라이브러리를 사용하는 것을 추천합니다.\n",
    "* 문장 속 모든 토큰을 각각의 벡터로 나누어 주기 위해 데이터셋의 모든 단어(토큰) 수 만큼의 벡터를 담는 사전(dictionary)를 정의해야 합니다. 이렇게 언어의 최소 단위인 토큰을 벡터 형태로 변환하는 작업을 워드 임베딩(word embedding)이라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c86074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-19T10:06:10.129093Z",
     "start_time": "2022-02-19T10:06:10.108115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.legacy import datasets, data # 자연어 데이터셋을 다루기 위해 토치비전이 아닌 토치 텍스트를 사용합니다.\n",
    "\n",
    "# 하이퍼파라미터 정의\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 10\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 기기로 학습합니다:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c32c21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-19T10:15:19.740377Z",
     "start_time": "2022-02-19T10:06:12.851174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 84.1M/84.1M [00:30<00:00, 2.80MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩하기\n",
    "# 텍스트 형태의 영화 리뷰들과 그에 해당하는 리뷰들을 텐서로 바꿔주기\n",
    "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
    "# sequential = True : 데이터셋이 순차적인 데이터셋임을 명시\n",
    "# batch_first = True : 신경망에 입력되는 텐서의 첫 번째 차원값을 batch size로 지정\n",
    "# lower = True : 텍스트 데이터 속 모든 영문 알파벳이 소문자가 되도록 처리\n",
    "LABEL = data.Field(sequential=False, batch_first=True) #Label은 순차적 데이터가 아님\n",
    "trainset, testset = datasets.IMDB.splits(TEXT, LABEL) # train test 분리\n",
    "TEXT.build_vocab(trainset, min_freq=5) # 워드 임베딩에 필요한 단어 사전(word vocabulary) 만들기\n",
    "# min_freq = 5 : 학습 데이터에서 최소 5번 이상 등장한 단어만을 사전에 담음\n",
    "LABEL.build_vocab(trainset)\n",
    "\n",
    "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
    "trainset, valset = trainset.split(split_ratio=0.8)\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False)\n",
    "\n",
    "\n",
    "vocab_size = len(TEXT.vocab) #사전 속 단어들의 개수와 레이블 수 지정\n",
    "n_classes = 2\n",
    "\n",
    "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
    "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2ce9e",
   "metadata": {},
   "source": [
    "* RNN의 입력이 길어지면 기울기(경사도) 폭발(gradient explosion) 혹은 기울기(경사도) 소실(vanishing gradient)이 발생 가능합니다\n",
    "* 이러한 단점이 보완된 것이 GRU(Gated Recurrent Unit)로, GRU는 시계열 데이터 속 벡터 사이의 정보 전달량을 조절함으로써 기울기를 적정하게 유지하고 문장 앞부분의 정보가 끝까지 도달할 수 있도록 돕습니다.\n",
    "* GRU에는 시계열 데이터 내 정보 전달량을 조절하는 업데이트 게이트(update gate)와 리셋 게이트(reset gate)라는 개념이 존재합니다.\n",
    "* 리셋 게이트는 새로운 입력이 이전 은닉 벡터와 어떻게 조합하는지를 결정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54208723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-19T11:06:53.035078Z",
     "start_time": "2022-02-19T11:06:53.005157Z"
    }
   },
   "outputs": [],
   "source": [
    "# RNN 모델 구현\n",
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        print(\"Building Basic GRU model...\")\n",
    "        self.n_layers = n_layers # 은닉 벡터들의 '층'이라고 할 수 있는 n_layers를 정의합니다.(보통 2이하로 정의)\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim) \n",
    "        # n_vocab : 전체 데이터셋의 모든 단어를 사전형태로 나타냈을 때 그 사전에 등재된 단어 수\n",
    "        # embed_dim : 임베딩된 단어 텐서가 지니는 차원 값\n",
    "        self.hidden_dim = hidden_dim # 은닉 벡터(hidden vector)의 차원값과 드롭아웃을 정의합니다.\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
    "                          num_layers=self.n_layers,\n",
    "                          batch_first=True) #위의 이유로 GRU를 사용합니다.\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes) # 압축된 텐서를 신경망에 통과시켜 예측을 출력합니다.\n",
    "\n",
    "    def forward(self, x): # 입력되는 x는 한 배치 속에 있는 모든 영화평입니다.\n",
    "        x = self.embed(x) # 워드 임베딩하면 시계열 데이터(벡터의 배열)로 변환됩니다.\n",
    "        h_0 = self._init_state(batch_size=x.size(0)) #첫 번쨰 은닉 벡터 H0를 정의해 x와 함께 입력해줍니다.\n",
    "        x, _ = self.gru(x, h_0)  # [i, b, h]\n",
    "        h_t = x[:,-1,:] # 영호 리뷰 배열들을 압축한 은닉벡터입니다.\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        # parameters() 함수는 신경망 모듈의 가중치 형태를 반복자(iterator) 형태를 반환합니다.\n",
    "        # 즉 weight는 nn.GRU 모듈의 첫 번째 가중치 텐서를 말합니다.\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d53a20d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-19T11:10:22.316758Z",
     "start_time": "2022-02-19T11:10:22.294820Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습함수와 평가함수 구현\n",
    "\n",
    "#학습함수\n",
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_iter): # 반복마다 배치 데이터를 반환합니다.\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)  # 1과 2의 레이블 값을 모든 값에서 1씩 빼서 0과 1로 변환\n",
    "        optimizer.zero_grad() # 매번 기울기를 새로 계산\n",
    "        logit = model(x) \n",
    "        loss = F.cross_entropy(logit, y) \n",
    "        loss.backward()\n",
    "        optimizer.step() #오차를 구하고 최적화 반복\n",
    "        \n",
    "#평가함수\n",
    "def evaluate(model, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction='sum') #오차의 합 구하기\n",
    "        total_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy #오찻값과 정확도의 평균 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8fa69bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-19T11:11:04.041491Z",
     "start_time": "2022-02-19T11:11:03.888890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU model...\n"
     ]
    }
   ],
   "source": [
    "# 모델 객체 정의\n",
    "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
    "# 모델 내 은닉벡터의 차원값 = 256, 임베딩된 토큰의 차원값 = 128로 임의 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) # 최적화 알고리즘으로 Adam 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f10f21af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-19T16:23:30.550158Z",
     "start_time": "2022-02-19T11:11:49.622405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[이폭: 1] 검증 오차: 0.70 | 검증 정확도:50.48\n",
      "[이폭: 2] 검증 오차: 0.58 | 검증 정확도:70.46\n",
      "[이폭: 3] 검증 오차: 0.40 | 검증 정확도:82.20\n",
      "[이폭: 4] 검증 오차: 0.32 | 검증 정확도:86.80\n",
      "[이폭: 5] 검증 오차: 0.37 | 검증 정확도:85.78\n",
      "[이폭: 6] 검증 오차: 0.39 | 검증 정확도:86.40\n",
      "[이폭: 7] 검증 오차: 0.44 | 검증 정확도:85.26\n",
      "[이폭: 8] 검증 오차: 0.48 | 검증 정확도:85.02\n",
      "[이폭: 9] 검증 오차: 0.48 | 검증 정확도:86.42\n",
      "[이폭: 10] 검증 오차: 0.48 | 검증 정확도:85.46\n"
     ]
    }
   ],
   "source": [
    "# 검증오차(val_loss) 최소화된 모델 저장\n",
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
    "    \n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3056d531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-19T17:16:31.729965Z",
     "start_time": "2022-02-19T17:13:07.855946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차:  0.32 | 테스트 정확도: 86.66\n"
     ]
    }
   ],
   "source": [
    "# 검증셋에서 가장 성능이 좋았던 모델을 불러와 테스트\n",
    "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iter)\n",
    "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b4c5b",
   "metadata": {},
   "source": [
    "### Seq2Seq 기계 번역"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600042e",
   "metadata": {},
   "source": [
    "* 2010년 이후 인공지능에서 가장 큰 관심을 받은 건 알파고지만, 그와 더불어 크게 화제가 된 머신러닝 모델이 언어를 다른 언어로 해석해주는 뉴럴 기계 번역(Neural Machine Translation)모델입니다.\n",
    "* RNN 기반의 번역 모델인 Sequence to Sequence (줄여서 Seq2Seq) 모델은 기계 번역의 새로운 패러다임을 열었다고 할 정도로 뛰어난 성능을 보여줬습니다.\n",
    "* Seq2Seq 모델은 시퀀스(Sequence)를 입력받아 또 다른 시퀀스를 출력합니다. 한마디로 문장을 다른 문장으로 번역해주는 모델입니다.\n",
    "* 일반적으로 Seq2Seq와 같은 기계 번역 모델이 이러한 능력을 학습하려면 흔히 병렬 말뭉치(parallel corpora)라고 하는 원문과 번역문이 쌍을 이루는 형태의 많은 텍스트 데이터가 필요합니다. 따라서 이런 모델을 제대로 학습시키려면 당연히 강력한 GPU, 복잡한 텍스트 전처리 과정, 긴 학습시간 등 많은 리소스가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d0eb6b",
   "metadata": {},
   "source": [
    "따라서, 이번 예제에서는 Seq2Seq 모델을 아주 간소화하여 한 언어의 문장을 다른 언어의 문장으로 번역하는 덩치 큰 모델이 아닌, 영어 알파벳 문자열 \"hello\"를 스페인어 알파벳 문자열 \"hola\"로 번역하는 미니 Seq2Seq 모델을 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f831a",
   "metadata": {},
   "source": [
    "#### 개요\n",
    "* Seq2Seq는 각자 다른 역할을 하는 두 개의 RNN을 이어붙인 모델입니다. \n",
    "* 번역은 1. 원문을 이해하고, 2. 번역문을 작성하는 두 가지 동작으로 구성되는데, Seq2Seq 모델에서 이 두 역할을 각각 인코더(encoder)와 디코더(decoder)라는 두 RNN에 부여함으로써 번역합니다.\n",
    "* 인코더는 원문 속의 모든 단어를 입력받아 문장의 뜻을 내포하는 고정 크기의 텐서를 만들어냅니다. 이렇게 압축된 텐서는 원문의 뜻과 내용을 압축하고 있다고 하여 문맥 벡터(context vector)라고 합니다. 인코더 RNN은 원문 속의 토큰을 차례대로 입력받습니다. 원문 마지막 토큰에 해당하는 은닉 벡터는 원문의 뜻을 모두 내포하는 문맥 벡터입니다.\n",
    "* 디코더 또한 RNN 모델로, 인코더에서 원문 문맥 벡터를 이어받아 번역문 속의 토큰을 차례대로 예상합니다. 번역할 때 '원문이 말하는 바가 무엇인가'를 항상 생각하고 있어야 합니다. 이는 디코더가 번역문의 단어나 토큰을 출력할 때 인코더로부터 정보를 전달받아야 한 다는 뜻이기도 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5719430f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T03:19:47.177611Z",
     "start_time": "2022-02-20T03:19:35.853471Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델구현하기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b625638",
   "metadata": {},
   "source": [
    "한 언어로 된 문장을 다른 언어로 번역하는 작업을 할 때는 보통 단어를 문장의 최소단위로 여겨 단어 단위의 임베딩(word embedding)을 하지만 이번 예제에선 간단한 영단어 \"hello\"를 스페인어 \"hola\"로 번역하는 작업을 할 것이므로 이번 예제에서는 단어 단위의 워드 임베딩이 아닌 글자 단위의 캐릭터 임베딩(Character embedding)을 사용하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fb652a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T03:21:12.846776Z",
     "start_time": "2022-02-20T03:21:12.828827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 256  # 총 아스키 코드 개수 (아스키 코드: 영문을 숫자로 변환하는 방식)\n",
    "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
    "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca42ffb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T03:22:39.825546Z",
     "start_time": "2022-02-20T03:22:39.808593Z"
    }
   },
   "outputs": [],
   "source": [
    "# 아스키 코드 리스트를 파이토치 텐서로 변환\n",
    "x = torch.LongTensor(x_)\n",
    "y = torch.LongTensor(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcc501f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T03:29:59.285468Z",
     "start_time": "2022-02-20T03:29:59.251558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seq2Seq 모델 클래스 정의\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size) # hidden_size가 임베딩된 토큰의 차원값\n",
    "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.decoder = nn.GRU(hidden_size, hidden_size) # encoder와 decoder 객체는 GRU\n",
    "        self.project = nn.Linear(hidden_size, vocab_size) # 번역문의 다음 토큰을 예상해내는 신경망\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 인코더에 들어갈 입력\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)\n",
    "        # embedding = [seq_len, batch_size, embedding_size]\n",
    "        \n",
    "        # 인코더 (Encoder)\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
    "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
    "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
    "\n",
    "        # 디코더에 들어갈 입력\n",
    "        decoder_state = encoder_state # 원문을 인코더에 입력시킨 문맥벡터 : encoder_state , 디코더의 첫 번째 은닉벡터 : decoder_state\n",
    "        decoder_input = torch.LongTensor([0]) # 0 : 아스키값의 공백 문자(null)를 뜻함\n",
    "        \n",
    "        # 디코더 (Decoder)\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(targets.size()[0]): #\"hola\"의 \"h\" 다음에 올 문자가 \"o\"임을 예측하기 위한 for 반복문\n",
    "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "            projection = self.project(decoder_output)\n",
    "            outputs.append(projection) # 디코더의 출력값으로 다음 글자 예측하기\n",
    "            \n",
    "            # 티처 포싱(Teacher Forcing) 사용\n",
    "            # 티처 포싱: 디코더 학습시 실제 번역문의 토큰을 디코더의 전 출력값 대신 입력으로 사용해 학습을 가속하는 방법\n",
    "            decoder_input = torch.LongTensor([targets[i]])\n",
    "\n",
    "        outputs = torch.stack(outputs).squeeze() # 번역문의 모든 토큰에 대한 결괏값들의 배열\n",
    "        return outputs\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2528d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T03:30:50.851710Z",
     "start_time": "2022-02-20T03:30:50.838639Z"
    }
   },
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(vocab_size, 16)\n",
    "criterion = nn.CrossEntropyLoss() # 교차 엔트로피 오차를 구하는 CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3) # 최적화 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b952618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T03:31:19.345212Z",
     "start_time": "2022-02-20T03:31:06.886214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 반복:0 오차: 5.626200199127197\n",
      "['z', 'Ë', 'C', 'C']\n",
      "\n",
      " 반복:100 오차: 1.897092342376709\n",
      "['h', 'h', 'l', 'a']\n",
      "\n",
      " 반복:200 오차: 0.6785041093826294\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:300 오차: 0.42450815439224243\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:400 오차: 0.3090987205505371\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:500 오차: 0.22862359881401062\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:600 오차: 0.17039543390274048\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:700 오차: 0.12842020392417908\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:800 오차: 0.09987519681453705\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:900 오차: 0.08031516522169113\n",
      "['h', 'o', 'l', 'a']\n"
     ]
    }
   ],
   "source": [
    "# 1000번의 이폭에 걸쳐 모델 학습\n",
    "log = []\n",
    "for i in range(1000):\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        print([chr(c) for c in top1.squeeze().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1c9a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T03:31:50.335128Z",
     "start_time": "2022-02-20T03:31:49.731732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 맷플롯립을 통한 오차가 줄어드는 모습 확인\n",
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ffd50b",
   "metadata": {},
   "source": [
    "오늘은 영화평 데이터를 이용해 RNN의 기본적인 쓰임새를 배우고, RNN의 단점을 보완한 GRU 모델을 이용해 텍스트 감정 분석 모델을 학습시켜보았습니다. 또한, 간단한 기계 번역 모델을 구현하여 기본적인 기계 번역 작동 원리 또한 알아보았습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
